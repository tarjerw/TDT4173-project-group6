{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML project (data analysis).ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarjerw/TDT4173-project-group6/blob/main/ML_project_(data_analysis).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMXn-88OmVNA"
      },
      "source": [
        "#Data analysis\n",
        "\n",
        "In this code we present the data used in the paper: *Affiliation analysis of political tweets*\n",
        "\n",
        "The information obtained in the code is presented and discussed in the paper in section *3. Data*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mOf8oTfnQFV"
      },
      "source": [
        "##Import Libraries\n",
        "The main libraries imported are numpy, pandas, matplotlib, sklearn"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDX2HpAbVCwU"
      },
      "source": [
        "#import libraries for data manipulation and analysis   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#import these to count the occurence of words in the datasets\n",
        "import sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZom6A0JPscH"
      },
      "source": [
        "##Retrieve data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvhRzsKoGpGc"
      },
      "source": [
        "#retrieves data\n",
        "tweets2016_df = pd.read_csv('TweetDatabase_2016.csv')\n",
        "tweets2020_df = pd.read_csv('TweetDatabase_2020.csv')\n",
        "tweets2016_df.drop_duplicates()\n",
        "tweets2020_df.drop_duplicates()\n",
        "df_all = tweets2020_df.append(tweets2016_df) #set which dataset to use (2016 or 2020)\n",
        "\n",
        "#shuffles data\n",
        "df_all = df_all.sample(frac = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwd3OExyqpfI"
      },
      "source": [
        "##Number of democrat and republican tweets\n",
        "\n",
        "The information retreived from the data is presented in the paper in section *3. Data*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmDRqfADfdIZ"
      },
      "source": [
        "#counts the number of democrat tweets and republican tweets\n",
        "print('Total number of Tweets \\n'+str(df_all.Party.value_counts()), '\\n')\n",
        "print(\"2016: \\n\"+str(tweets2016_df.Party.value_counts()), '\\n')\n",
        "print(\"2020: \\n\"+str(tweets2020_df.Party.value_counts()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FjTtTDOYq2bc"
      },
      "source": [
        "##Number of tweets per candidate\n",
        "\n",
        "The information retreived from the data is presented in the paper in section *3.1 Data gathering process*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7DKaObXiOVK"
      },
      "source": [
        "#counts the number of tweets by each candidate\n",
        "print(\"2016: \\n\"+str(tweets2016_df.Candidate.value_counts()), '\\n')\n",
        "print(\"2020: \\n\"+str(tweets2020_df.Candidate.value_counts()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "crtXnwhoamMy"
      },
      "source": [
        "###Comparing frequency of words between parties\n",
        "\n",
        "Here we create a function that counts the number of occurences of a given word in republican and democrat words.\n",
        "\n",
        "The information retreived from the data is presented in the paper in section *3. Data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "quWu2RtWa5L2"
      },
      "source": [
        "# Create a dataset for each party containing only that parties tweets\n",
        "data_rep = df_all.loc[df_all['Party'] == 'Republican']\n",
        "data_dem = df_all.loc[df_all['Party'] == 'Democrat']\n",
        "\n",
        "# Create a vocabulary to the republican tweets dataset\n",
        "rep_BagOfWords_vectorizer = CountVectorizer(max_df=0.5, min_df=2, stop_words='english')\n",
        "data_rep_BagOfWords = rep_BagOfWords_vectorizer.fit_transform(data_rep.Tweet)\n",
        "\n",
        "# Create a vocabulary to the democrat tweets dataset\n",
        "dem_BagOfWords_vectorizer = CountVectorizer(max_df=0.5,min_df=2, stop_words='english')\n",
        "data_dem_BagOfWords = dem_BagOfWords_vectorizer.fit_transform(data_dem.Tweet)\n",
        "\n",
        "# Count the occurence of words in the republican tweets dataset\n",
        "freqs_rep = zip(rep_BagOfWords_vectorizer.get_feature_names(), data_rep_BagOfWords.sum(axis=0).tolist()[0])    \n",
        "freqs_list_rep = list(freqs_rep)\n",
        "sorted_freps_rep = sorted(freqs_list_rep, key=lambda x: -x[1])\n",
        "\n",
        "# Count the occurence of words in the republican tweets dataset\n",
        "freqs_dem = zip(dem_BagOfWords_vectorizer.get_feature_names(), data_dem_BagOfWords.sum(axis=0).tolist()[0])    \n",
        "freqs_list_dem = list(freqs_dem)\n",
        "sorted_freps_dem = sorted(freqs_list_dem, key=lambda x: -x[1])\n",
        "\n",
        "#filter on specific words: \n",
        "def WordtoFrequency(word):\n",
        "  print(\"word =\",word)\n",
        "  dem, rep= False, False\n",
        "  for i in range(len(sorted_freps_rep)):\n",
        "    if sorted_freps_rep[i][0] == word:\n",
        "      rep=True\n",
        "      print(\"Republican frequency:\",sorted_freps_rep[i][1])\n",
        "    elif i == len(sorted_freps_rep)-1 and not rep:\n",
        "      print(\"Republican frequency:\", 0)\n",
        "  for i in range(len(sorted_freps_dem)):\n",
        "    if sorted_freps_dem[i][0] == word:\n",
        "      dem=True\n",
        "      print(\"Democrat frequency:\",sorted_freps_dem[i][1])\n",
        "    elif i == len(sorted_freps_dem)-1 and not dem:\n",
        "      print(\"Democrat frequency:\", 0)\n",
        "  print()\n",
        "\n",
        "#call on the function to see the number of occurences of a given word in republican and democrat tweets\n",
        "WordtoFrequency(\"crooked\")\n",
        "WordtoFrequency(\"makeamericagreatagain\")\n",
        "WordtoFrequency(\"fake\")\n",
        "WordtoFrequency(\"crisis\")\n",
        "WordtoFrequency(\"climate\")\n",
        "WordtoFrequency(\"folks\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}