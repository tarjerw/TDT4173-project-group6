{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML project (BOW).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "RRm5q0kRHQXk",
        "DZom6A0JPscH",
        "fyygWCNVCal3",
        "FVEP-07qc9et",
        "bob8NcLkoB0C",
        "NCySJUzdDZat",
        "k-zxaKFaKWUQ",
        "oRI7CU1ZbNUy",
        "E3JCmEoLXvDS",
        "S3WYtd8ocLUH",
        "Ex0MwkPk2Psp",
        "4ZsldGUQAxRB"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tarjerw/TDT4173-project-group6/blob/main/ML_project_(BOW).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-InharmhPF7W"
      },
      "source": [
        "#Affiliation analysis of political tweets - Logistic regression\n",
        "\n",
        "This is the code used for training a logistic regression method to do political affiliation classification (democrat or republican) of tweets, and testing it on test data, discussed in the paper Affiliation analysis of politcal tweets. Logistic regression is disscussed in section *4.1 Logistic regression in using bag-of-words(BOW)* and *5.1 Logistic regression method results*\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRm5q0kRHQXk"
      },
      "source": [
        "## Import Libraries\n",
        "\n",
        "The main libraries imported are numpy, pandas, matplotlib, sklearn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RDX2HpAbVCwU"
      },
      "source": [
        "#import libraries for data manipulation and analysis   \n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "#plotting results\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#import the machine learning library: sklearn\n",
        "import sklearn\n",
        "\n",
        "#import bag of words of n-gram function (Countvectorizer) from sklearn\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "#import function that seperates a dataset into a training set and test set with proportions specified in parameters\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# import the machine learning method, Logistic Regression used to classify tweets\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# import cross validation score function that computes k-folds cross validation with k specified in parameters\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# import confusion matrix function from sklearn \n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# TableIt is an efficient 3rd party file for displaying resuls in table form in python. \n",
        "# This file must be added to Collab before running.\n",
        "import TableIt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZom6A0JPscH"
      },
      "source": [
        "##Data retrieval\n",
        "\n",
        "Data is retrieved from the 2 CSV files TweetDatabase_2016.csv, TweetDatabase_2020.csv that contain all tweets from 2016 and 2020 respectively.\n",
        "The files are first converted into pandas dataframes: df_2016, df_2020. Then they are merged together, and return a third dataset with both election years: df_2016_2020."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvhRzsKoGpGc"
      },
      "source": [
        "#Retrieve data from CSV files and convert to dataframes using pandas\n",
        "tweets2016_df = pd.read_csv('TweetDatabase_2016.csv')\n",
        "tweets2020_df = pd.read_csv('TweetDatabase_2020.csv')\n",
        "df_2016 = tweets2016_df \n",
        "df_2020 = tweets2020_df \n",
        "\n",
        "#All duplicates are removed from the dataframes, using .drop_duplicates()\n",
        "df_2016 = df_2016.drop_duplicates()\n",
        "df_2020 = df_2020.drop_duplicates() \n",
        "df_2016_2020 = df_2016.append(df_2020)\n",
        "\n",
        "#Shuffle data using the pandas function .samples()\n",
        "df_2016 = df_2016.sample(frac = 1)\n",
        "df_2020 = df_2020.sample(frac = 1)\n",
        "df_2016_2020 = df_2016_2020.sample(frac = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yWOpVu5OJwB"
      },
      "source": [
        "##Sentiment analysis using logistic regression with BOW & N-Gram\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyygWCNVCal3"
      },
      "source": [
        "###Splitting data\n",
        "\n",
        "The 3 datasets are split into two mutually exclusive and collectively exhaustive classes: 80% of the original datasets are labeled as training sets and the remaining 20% are labeled as test sets using the sklearn method train_test_split()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPAiM8lDhDKt"
      },
      "source": [
        "# Splits dataset into Training data and Test data, with 20% test data and 80% training data\n",
        "# In sklearn's train_test_split() method, the argument test_size=0.2 specifies that 20% of the data set should be labeled test data and the remaining 80% should be labeled training data.\n",
        "\n",
        "X_train16, X_test16, y_train16, y_test16 = train_test_split(df_2016.Tweet, df_2016.Party, test_size=0.2)\n",
        "X_train20, X_test20, y_train20, y_test20 = train_test_split(df_2020.Tweet, df_2020.Party, test_size=0.2)\n",
        "X_train1620, X_test1620, y_train1620, y_test1620 = train_test_split(df_2016_2020.Tweet, df_2016_2020.Party, test_size=0.2)\n",
        "\n",
        "# Prints the resulting training and test sets for all three datasets.\n",
        "print(\"Year 2016: \\n\"+\"Democratic republican ratio in Training data:\\n\"+str(y_train16.value_counts())+\"\\n\")\n",
        "print(\"Democratic republican ratio in Test data:\\n\"+str(y_test16.value_counts()),'\\n')\n",
        "print(\"-------------------------------------------------------\\n\")\n",
        "print(\"Year 2020: \\n\"+\"Democratic republican ratio in Training data:\\n\"+str(y_train20.value_counts())+\"\\n\")\n",
        "print(\"Democratic republican ratio in Test data:\\n\"+str(y_test20.value_counts()),'\\n')\n",
        "print(\"-------------------------------------------------------\\n\")\n",
        "print(\"Year 2016+2020: \\n\"+\"Democratic republican ratio in Training data:\\n\"+str(y_train1620.value_counts())+\"\\n\")\n",
        "print(\"Democratic republican ratio in Test data:\\n\"+str(y_test1620.value_counts()))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FVEP-07qc9et"
      },
      "source": [
        "###Transforming data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bob8NcLkoB0C"
      },
      "source": [
        "####Creating BOW model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1SFhnV7boofN"
      },
      "source": [
        "# Create Bag of words for each election year and preprocess data simultaneously using sklearns CountVectorizer() method.\n",
        "# Parameters:\n",
        "# max_df removes all words that are too frequent in the dataset \n",
        "# min_df removes all words that occur only once in the dataset \n",
        "# stop_words='english' removes most common, irrelevant english words\n",
        "BagOfWords_vectorizer16 = CountVectorizer(lowercase=True, max_df=0.35, min_df=2, stop_words='english')\n",
        "BagOfWords_vectorizer20 = CountVectorizer(lowercase=True, max_df=0.35, min_df=2, stop_words='english')\n",
        "BagOfWords_vectorizer1620 = CountVectorizer(lowercase=True, max_df=0.35, min_df=2, stop_words='english')\n",
        "\n",
        "# Learn the vocabulary of the training data and convert the training data into a document term matrix\n",
        "# Parameters:\n",
        "# fit(train_data) = learn the vocabulary of the training data\n",
        "# transform(train_data) = convert the training data into a document term matrix\n",
        "# fit_transform(train_data) = fit(train_data) + transform(train_data)\n",
        "# transform(test_data) = use the fitted vocabulary (training) to build a document term matrix from the testing data\n",
        "\n",
        "# 2016 dataset\n",
        "X_train_BagOfWords16 = BagOfWords_vectorizer16.fit_transform(X_train16) \n",
        "X_test_BagOfWords16 = BagOfWords_vectorizer16.transform(X_test16)\n",
        "\n",
        "# 2020 dataset\n",
        "X_train_BagOfWords20 = BagOfWords_vectorizer20.fit_transform(X_train20)\n",
        "X_test_BagOfWords20 = BagOfWords_vectorizer20.transform(X_test20)\n",
        "\n",
        "# 20216-20 dataset\n",
        "X_train_BagOfWords1620 = BagOfWords_vectorizer1620.fit_transform(X_train1620)\n",
        "X_test_BagOfWords1620 = BagOfWords_vectorizer1620.transform(X_test1620)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCySJUzdDZat"
      },
      "source": [
        "####Creating N-Gram model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jk8tS1kZDkUM"
      },
      "source": [
        "# Create N-Gram for each election year and preprocess data simultaneously using sklearns CountVectorizer() method.\n",
        "# Parameters:\n",
        "# max_df removes all words that are too frequent in the dataset \n",
        "# min_df removes all words that occur only once in the dataset \n",
        "# using sklearn function CountVectorizer() and including parameter ngram_range=(1,4) to create a vocabulary of phrases from 1 to 4 words.\n",
        "N_Gram_vectorizer16 = CountVectorizer(ngram_range=(1,4), max_df=0.35, min_df=2)\n",
        "N_Gram_vectorizer20 = CountVectorizer(ngram_range=(1,4), max_df=0.35, min_df=2)\n",
        "N_Gram_vectorizer1620 = CountVectorizer(ngram_range=(1,4), max_df=0.35, min_df=2)\n",
        "\n",
        "# 2016 dataset\n",
        "X_train_N_Gram16 = N_Gram_vectorizer16.fit_transform(X_train16)\n",
        "X_test_N_Gram16 = N_Gram_vectorizer16.transform(X_test16)\n",
        "\n",
        "# 2020 dataset\n",
        "X_train_N_Gram20 = N_Gram_vectorizer20.fit_transform(X_train20)\n",
        "X_test_N_Gram20 = N_Gram_vectorizer20.transform(X_test20)\n",
        "\n",
        "# 2016-20 dataset\n",
        "X_train_N_Gram1620 = N_Gram_vectorizer1620.fit_transform(X_train1620)\n",
        "X_test_N_Gram1620 = N_Gram_vectorizer1620.transform(X_test1620)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wDIaIGzRCGSX"
      },
      "source": [
        "###Logistic regression using BOW\n",
        "\n",
        "How well does the training data predict the test data?\n",
        "\n",
        "To create a logistic regression model we used sklearn machine learning built in logistic regression model (see imports) and tuned its hyperparameter C to find its optimal value. A theoretical description of the logistic regression method and its use case in the paper is discussed in section *4.1 Logistic regression using bag-of-words (BOW)*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-zxaKFaKWUQ"
      },
      "source": [
        "####Tunning hyperparameter C\n",
        "\n",
        "Vizualization of varying hyperparameter C in logistic regression on train and test accuracies.\n",
        "This topic is discussed in the paper in *section 5.1.2 Tuning hyperparameter C, regularization parameter.*\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64yVS3enKUiT"
      },
      "source": [
        "#Vizualization of varying hyperparameter C in Logistic regression using Bag of words on train and test accuracies\n",
        "\n",
        "acc_table_train16 = []\n",
        "acc_table_test16 = []\n",
        "acc_table_train20 = []\n",
        "acc_table_test20 = []\n",
        "acc_table_train1620 = []\n",
        "acc_table_test1620 = []\n",
        "# list of C values that the logistic regression models are tuned on\n",
        "param_range= [0.001,0.01,0.05,0.1,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0,2.5,3,3.5,4,5,6,7,8,9,10]\n",
        "\n",
        "# creating 3 horizontally aligned subplots\n",
        "fig, axs = plt.subplots(1, 3, sharey='row', figsize=(22.5,8))\n",
        "\n",
        "for i in param_range:\n",
        "  #Apply logistic regression model to training data and estimate the model through tuning  hyperparamter c with the param_range list given above\n",
        "  logit_BoW_16 = LogisticRegression(C=i)\n",
        "  logit_BoW_20 = LogisticRegression(C=i)\n",
        "  logit_BoW_1620 = LogisticRegression(C=i)\n",
        "\n",
        "  #Fits the model according to the given training data.\n",
        "  logit_BoW_16.fit(X_train_BagOfWords16, y_train16) \n",
        "  logit_BoW_20.fit(X_train_BagOfWords20, y_train20) \n",
        "  logit_BoW_1620.fit(X_train_BagOfWords1620, y_train1620) \n",
        "\n",
        "  #Predict test set using logistic regression and a given C\n",
        "  acc_table_test16.append(logit_BoW_16.score(X_test_BagOfWords16, y_test16))\n",
        "  acc_table_train16.append(logit_BoW_16.score(X_train_BagOfWords16, y_train16))\n",
        "  acc_table_test20.append(logit_BoW_20.score(X_test_BagOfWords20, y_test20))\n",
        "  acc_table_train20.append(logit_BoW_20.score(X_train_BagOfWords20, y_train20))\n",
        "  acc_table_test1620.append(logit_BoW_1620.score(X_test_BagOfWords1620, y_test1620))\n",
        "  acc_table_train1620.append(logit_BoW_1620.score(X_train_BagOfWords1620, y_train1620))\n",
        "\n",
        "#Vizualization of results\n",
        "axs[0].plot(param_range, acc_table_train16, label=\"Train score\", color=\"g\")\n",
        "axs[0].plot(param_range, acc_table_test16,  label=\"Test score\", color=\"r\")\n",
        "axs[0].set_title('2016')\n",
        "axs[1].plot(param_range, acc_table_train20, label=\"Train score\", color=\"g\")\n",
        "axs[1].plot(param_range, acc_table_test20, label=\"Test score\", color=\"r\")\n",
        "axs[1].set_title('2020')\n",
        "axs[2].plot(param_range, acc_table_train1620, label=\"Train score\", color=\"g\")\n",
        "axs[2].plot(param_range, acc_table_test1620, label=\"Test score\", color=\"r\")\n",
        "axs[2].set_title('2016-20')\n",
        "fig.suptitle('Accuracy of the logistic regression using BOW in all datasets')\n",
        "axs[0].set(xlabel='C value', ylabel='Accuracy')\n",
        "axs[1].set(xlabel='C value')\n",
        "axs[2].set(xlabel='C value')\n",
        "fig.subplots_adjust(wspace=0.05, hspace=0.05)\n",
        "axs[0].grid()\n",
        "axs[1].grid()\n",
        "axs[2].grid()\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.2)\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRI7CU1ZbNUy"
      },
      "source": [
        "####Accuracy results\n",
        "\n",
        "Accuracy of the logistic regression with BOW for all three datasets: 2016, 2020, 2016-20. These results are presented and discussed in the paper in section *5.1.3 Key results for bag-of-words and n-gram*.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3waXtsfqGWR"
      },
      "source": [
        "# With what accuracy does the logistic regression with BOW predict the political affiliation of tweets in the test sets for all three datasets: 2016, 2020, 2016-20\n",
        "\n",
        "logit_BoW_16 = LogisticRegression(C=1)\n",
        "logit_BoW_20 = LogisticRegression(C=1)\n",
        "logit_BoW_1620 = LogisticRegression(C=1)\n",
        "\n",
        "logit_BoW_16.fit(X_train_BagOfWords16, y_train16) \n",
        "logit_BoW_20.fit(X_train_BagOfWords20, y_train20) \n",
        "logit_BoW_1620.fit(X_train_BagOfWords1620, y_train1620) \n",
        "\n",
        "myList = [\n",
        "    [\"Year\",\"Machine Learning method\",\"Classifier\",\"Testset accuracy C=1\",],\n",
        "    [\"2016\", \"Bag of Words\", \"Logistic Regression\", round(logit_BoW_16.score(X_test_BagOfWords16, y_test16)*100,3)],\n",
        "    [\"2020\", \"Bag of Words\", \"Logistic Regression\", round(logit_BoW_20.score(X_test_BagOfWords20, y_test20)*100,3)],\n",
        "    [\"2016+2020\", \"Bag of Words\", \"Logistic Regression\", round(logit_BoW_1620.score(X_test_BagOfWords1620, y_test1620)*100,3)]\n",
        "]\n",
        "\n",
        "TableIt.printTable(myList, useFieldNames=True)\n",
        "print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n6VoKzEkKdaF"
      },
      "source": [
        "###Logistic regression using N-Gram\n",
        "A theoretical description of the logistic regression method and its use case in the paper is discussed in section *4.1 Logistic regression using bag-of-words (BOW)*."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3JCmEoLXvDS"
      },
      "source": [
        "####Tunning hyperparameter C\n",
        "\n",
        "This topic is discussed in the paper in section *5.1.2 Tuning hyperparameter C, regularization parameter*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAbBuXZ6s9gO"
      },
      "source": [
        "#Vizualization of varying hyperparameter C in the N-Gram model on train and test accuracies\n",
        "\n",
        "acc_table_train16 = []\n",
        "acc_table_test16 = []\n",
        "acc_table_train20 = []\n",
        "acc_table_test20 = []\n",
        "acc_table_train1620 = []\n",
        "acc_table_test1620 = []\n",
        "# list of C values that the logistic regression models are tuned on\n",
        "param_range= [0.005,0.001,0.01,0.05,0.1,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0,2.5,3,3.5,4,5,6,7,8,9,10]\n",
        "\n",
        "fig, axs = plt.subplots(1, 3, sharey='row', figsize=(22.5,8))\n",
        "for i in param_range:\n",
        "  #Apply logistic regression model to training data\n",
        "  logit_NG_16 = LogisticRegression(C=i)\n",
        "  logit_NG_20 = LogisticRegression(C=i)\n",
        "  logit_NG_1620 = LogisticRegression(C=i)\n",
        "\n",
        "  #Fits the model according to the given training data.\n",
        "  logit_NG_16.fit(X_train_N_Gram16, y_train16) \n",
        "  logit_NG_20.fit(X_train_N_Gram20, y_train20) \n",
        "  logit_NG_1620.fit(X_train_N_Gram1620, y_train1620) \n",
        "\n",
        "  #Predict test set using logistic regression and a given C\n",
        "  acc_table_test16.append(logit_NG_16.score(X_test_N_Gram16, y_test16))\n",
        "  acc_table_train16.append(logit_NG_16.score(X_train_N_Gram16, y_train16))\n",
        "  acc_table_test20.append(logit_NG_20.score(X_test_N_Gram20, y_test20))\n",
        "  acc_table_train20.append(logit_NG_20.score(X_train_N_Gram20, y_train20))\n",
        "  acc_table_test1620.append(logit_NG_1620.score(X_test_N_Gram1620, y_test1620))\n",
        "  acc_table_train1620.append(logit_NG_1620.score(X_train_N_Gram1620, y_train1620))\n",
        "\n",
        "#Vizualization of results\n",
        "axs[0].plot(param_range, acc_table_train16, label=\"Train score\", color=\"g\")\n",
        "axs[0].plot(param_range, acc_table_test16, label=\"Test score\", color=\"r\")\n",
        "axs[0].set_title('2016')\n",
        "axs[1].plot(param_range, acc_table_train20, label=\"Train score\", color=\"g\")\n",
        "axs[1].plot(param_range, acc_table_test20, label=\"Test score\", color=\"r\")\n",
        "axs[1].set_title('2020')\n",
        "axs[2].plot(param_range, acc_table_train1620, label=\"Train score\", color=\"g\")\n",
        "axs[2].plot(param_range, acc_table_test1620, label=\"Test score\", color=\"r\")\n",
        "axs[2].set_title('2016 - 20')\n",
        "fig.suptitle('Accuracy of the logistic regression using n-gram in all datasets')\n",
        "axs[0].set(xlabel='C value', ylabel='Accuracy')\n",
        "axs[1].set(xlabel='C value')\n",
        "axs[2].set(xlabel='C value')\n",
        "fig.subplots_adjust(wspace=0.1, hspace=0.1)\n",
        "axs[0].grid()\n",
        "axs[1].grid()\n",
        "axs[2].grid()\n",
        "plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\n",
        "\n",
        "fig.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3WYtd8ocLUH"
      },
      "source": [
        "####Accuracy results\n",
        "\n",
        "Accuracy of the logistic regression with N-Gram for all three datasets: 2016, 2020, 2016-20.\n",
        "These results are presented and discussed in the paper in *section 5.1.3 Key results for bag-of-words and n-gram*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq8lv-qxqu4G"
      },
      "source": [
        "# How well does the N-Gram training data predict the test set for all three datasets: 2016, 2020, 2016-20\n",
        "\n",
        "#Apply logistic regression model to training data\n",
        "logit_NG_16 = LogisticRegression(C=1)\n",
        "logit_NG_20 = LogisticRegression(C=1)\n",
        "logit_NG_1620 = LogisticRegression(C=1)\n",
        "\n",
        "#Fits the model according to the given training data.\n",
        "logit_NG_16.fit(X_train_N_Gram16, y_train16) \n",
        "logit_NG_20.fit(X_train_N_Gram20, y_train20) \n",
        "logit_NG_1620.fit(X_train_N_Gram1620, y_train1620) \n",
        "\n",
        "myList = [\n",
        "    [\"Year\",\"Machine Learning method\",\"Classifier\",\"Testset accuracy C=1\"],\n",
        "    [\"2016\", \"N-Gram\", \"Logistic Regression\", round(logit_NG_16.score(X_test_N_Gram16, y_test16)*100,3)],\n",
        "    [\"2020\", \"N-Gram\", \"Logistic Regression\", round(logit_NG_20.score(X_test_N_Gram20, y_test20)*100,3)],\n",
        "    [\"2016+2020\", \"N-Gram\", \"Logistic Regression\", round(logit_NG_1620.score(X_test_N_Gram1620, y_test1620)*100,3)]\n",
        "]\n",
        "\n",
        "TableIt.printTable(myList, useFieldNames=True)\n",
        "print('')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ex0MwkPk2Psp"
      },
      "source": [
        "###Cross validation on both models\n",
        "\n",
        "We use a k-folds cross validation technique with 5 folds.\n",
        "\n",
        "Steps of k-folds cross validation method:\n",
        "*   Partition the data into a number of subsets\n",
        "*   Hold out a set at a time and train the model on remaining set\n",
        "*   Test model on hold out set\n",
        "*   Repeat the process for each subset of the dataset\n",
        "\n",
        "Cross validation is presented and discussed in the paper in section *5.1.1    Cross validation*."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kt-a2v4Bk3c2"
      },
      "source": [
        "# Cross-validation is a statistical method that can be used to verify the level of overfitting in machine learning models.\n",
        "# For computing cross validation we used sklearn cross_val_score() function that returns a list of k accuracies, one for each tested subset in the training data.\n",
        "# Parameters\n",
        "# Logistic regression: training a model with logistic regression and its hyperparameter set to 1\n",
        "# X_train_BagOfWords16 and y_train16\n",
        "# we use cross validation with 5 folds: cv=5, giving 80% training and 20% test data\n",
        "\n",
        "# Cross validation on bag of words datasets\n",
        "scores_BagOfWords16 = cross_val_score(LogisticRegression(C=1), X_train_BagOfWords16, y_train16, cv=5) # 2016 dataset\n",
        "scores_BagOfWords20 = cross_val_score(LogisticRegression(C=1), X_train_BagOfWords20, y_train20, cv=5) # 2020 dataset\n",
        "scores_BagOfWords1620 = cross_val_score(LogisticRegression(C=1), X_train_BagOfWords1620, y_train1620, cv=5) # 2016-20 dataset\n",
        "\n",
        "# Cross validation on n-gram datasets\n",
        "scores_N_Gram16 = cross_val_score(LogisticRegression(C=1), X_train_N_Gram16, y_train16, cv=5) # 2016 dataset\n",
        "scores_N_Gram20 = cross_val_score(LogisticRegression(C=1), X_train_N_Gram20, y_train20, cv=5) # 2020 dataset\n",
        "scores_N_Gram1620 = cross_val_score(LogisticRegression(C=1), X_train_N_Gram1620, y_train1620, cv=5) # 2016-20 dataset\n",
        "\n",
        "# Returns a table illustrating the cross validation scores of the training sets for both methods in 2016 and 2020.\n",
        "myList = [\n",
        "    [\"Year      | Method\", \"Cross Validation scores\", \"Mean accuracy\"],\n",
        "    [\"2016      | Bag-of-Words\",scores_BagOfWords16,sum(scores_BagOfWords16)/len(scores_BagOfWords16)],\n",
        "    [\"          | N-Gram\",scores_N_Gram16, sum(scores_N_Gram16)/len(scores_N_Gram16)],\n",
        "    [\"2020      | Bag-of-Words\",scores_BagOfWords20, sum(scores_BagOfWords20)/len(scores_BagOfWords20)],\n",
        "    [\"          | N-Gram\",scores_N_Gram20, sum(scores_N_Gram20)/len(scores_N_Gram20)],\n",
        "    [\"2016+2020 | Bag-of-Words\",scores_BagOfWords1620, sum(scores_BagOfWords1620)/len(scores_BagOfWords1620)],\n",
        "    [\"          | N-Gram\",scores_N_Gram1620 , sum(scores_N_Gram1620)/len(scores_N_Gram1620)]\n",
        "]\n",
        "TableIt.printTable(myList, useFieldNames=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZsldGUQAxRB"
      },
      "source": [
        "###Confusion Matrix\n",
        "\n",
        "By definition a confusion matrix C is such that Cij is equal to the number of observations known to be in group i and predicted to be in group j.\n",
        "\n",
        "Thus in our binary classification, the count of true Republican tweets is C[0][0] and false Republican tweets is C[1][0]. Likewise, the count of true Democrat tweets is C[0][1], and false Democrat tweets C[1][1].\n",
        "\n",
        "These results are analyzed in section 5.1.3 Key results for bag-of-words and n-gram."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4_Mua4Tuvs1"
      },
      "source": [
        "pred_lr_bow16 = logit_BoW_16.predict(X_test_BagOfWords16)\n",
        "pred_lr_bow20 = logit_BoW_20.predict(X_test_BagOfWords20)\n",
        "pred_lr_bow1620 = logit_BoW_1620.predict(X_test_BagOfWords1620)\n",
        "\n",
        "pred_lr_ng16 = logit_NG_16.predict(X_test_N_Gram16)\n",
        "pred_lr_ng20 = logit_NG_20.predict(X_test_N_Gram20)\n",
        "pred_lr_ng1620 = logit_NG_1620.predict(X_test_N_Gram1620)\n",
        "\n",
        "\n",
        "confB16 = confusion_matrix(y_test16, pred_lr_bow16)\n",
        "confB20 = confusion_matrix(y_test20, pred_lr_bow20)\n",
        "confB1620 = confusion_matrix(y_test1620, pred_lr_bow1620)\n",
        "confNG16 = confusion_matrix(y_test16, pred_lr_ng16)\n",
        "confNG20 = confusion_matrix(y_test20, pred_lr_ng20)\n",
        "confNG1620 = confusion_matrix(y_test1620, pred_lr_ng1620)\n",
        "\n",
        "\n",
        "print(\"Confusion matrix\")\n",
        "myList = [\n",
        "    [\"Year\",\"ML method\",\"Classifier\",\"True Democrat\", \"False Republican\",\"False Democrat\", \"True Republican\"],\n",
        "    [\"2016\", \"Bag of Words\", \"Log Reg\", confB16[0][0], confB16[0][1], confB16[1][0], confB16[1][1]],\n",
        "    [\"2016\", \"N-Gram\", \"Log Reg\", confNG16[0][0], confNG16[0][1], confNG16[1][0], confNG16[1][1]],\n",
        "    [\"2020\", \"Bag of Words\", \"Log Reg\", confB20[0][0], confB20[0][1], confB20[1][0], confB20[1][1]],\n",
        "    [\"2020\", \"N-Gram\", \"Log Reg\", confNG20[0][0], confNG20[0][1], confNG20[1][0], confNG20[1][1]],\n",
        "    [\"2016+2020\", \"Bag of Words\", \"Log Reg\", confB1620[0][0], confB1620[0][1], confB1620[1][0], confB1620[1][1]],\n",
        "    [\"2016+2020\", \"N-Gram\", \"Log Reg\", confNG1620[0][0], confNG1620[0][1], confNG1620[1][0], confNG1620[1][1]]\n",
        "]\n",
        "\n",
        "TableIt.printTable(myList, useFieldNames=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}